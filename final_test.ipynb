{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functions\n",
    "import nltk\n",
    "#nltk.download('punkt')  # Download the necessary tokenizer data (only required once)\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "openai.api_key = api_key  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"input_sample/BERT.pdf\"\n",
    "#test_query_raw = \"What is the key reference of the paper?\" # reference related\n",
    "test_query_raw = \"How does BERT address the limitations of current techniques?\" #direct query\n",
    "#test_query_raw = \"what is the key insight of the proposed method?\" #indirect query\n",
    "raw_text = functions.extract_raw_text_from_pdf(file_path)\n",
    "in_text_citations, cleaned_text = functions.extract_in_text_citations(raw_text)#cleaned_text is changed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_citation_context = pd.DataFrame(columns=['citation', 'context'])\n",
    "for citation in in_text_citations:\n",
    "    context = functions.get_context(raw_text, citation)\n",
    "    new_row = pd.DataFrame({'citation': [citation], 'context': [context]})\n",
    "    raw_citation_context = pd.concat([raw_citation_context, new_row], ignore_index=True)\n",
    "\n",
    "#raw_citation_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extract Refernces part\n",
    "references = re.findall(r'References.*', cleaned_text) \n",
    "# check if there is \"Appendix\" part after references\n",
    "appendix = re.findall(r'Appendix.*', cleaned_text)\n",
    "# find the word \"References\" and remove everything after it\n",
    "cleaned_text0 = re.sub(r'References.*', '', cleaned_text) + ' '.join(appendix)\n",
    "# add some key words to the beginning of the text\n",
    "cleaned_text = \"title \" + \"author \" + cleaned_text0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences = cleaned_text.split(' ')\n",
    "# split the text into chunks of 350 words with 50 words overlap\n",
    "chunks = [' '.join(all_sentences[i:i+250]) for i in range(0, len(all_sentences), 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [title, author, bert, pretraining, deep, bidir...\n",
       "1     [aim, predict, relationship, sentence, analyzi...\n",
       "2     [harmful, applying, ﬁnetuning, based, approach...\n",
       "3     [us, shallow, concatenation, independently, tr...\n",
       "4     [sentence, lefttoright, generation, next, sent...\n",
       "                            ...                        \n",
       "60    [semantically, equivalent, qnli, question, nat...\n",
       "61    [task, consisting, sentence, extracted, movie,...\n",
       "62    [report, singletask, ﬁnetuning, result, paper,...\n",
       "63    [ablation, study, evaluate, effect, different,...\n",
       "64    [target, token, themask, symbol, mlm, ame, mea...\n",
       "Name: text, Length: 65, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with the chunks\n",
    "raw_df = pd.DataFrame(chunks, columns=['text'])\n",
    "# process the sentences\n",
    "df = raw_df['text'].apply(functions.process_sentence)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_test_query = functions.process_sentence(test_query_raw)\n",
    "# remove \"paper\",\"text\",\"article\",\"thesis\" from the query\n",
    "in_test_query = [x for x in in_test_query if x not in [\"paper\",\"text\",\"article\",\"thesis\"]]\n",
    "\n",
    "# if the query contains 'reference','references' or 'citation' ,'citations'\n",
    "if any(x in in_test_query for x in ['reference','references','citation','citations']):\n",
    "    df_chosen_temp = raw_citation_context\n",
    "    # set the citation as the index of the dataframe\n",
    "    df_chosen_temp = df_chosen_temp.set_index('citation')\n",
    "    # df_chosen should be a dataframe series\n",
    "    df_chosen = df_chosen_temp['context']\n",
    "    # process the sentences\n",
    "    df_chosen = df_chosen.apply(functions.process_sentence)\n",
    "    test_query = in_test_query\n",
    "\n",
    "else:\n",
    "    # find all the rows containing at least one word in the query\n",
    "    selected_rows = []\n",
    "    for i in range(len(df)):\n",
    "        if any(x in df[i] for x in in_test_query):\n",
    "            selected_rows.append(i)\n",
    "\n",
    "    # check if the query if direct in the text or not\n",
    "    if len(selected_rows) >= 1:\n",
    "        # extract the selected_rows from the dataframe with thier index and create a new dataframe\n",
    "        df_selected = df.iloc[selected_rows]\n",
    "        df_chosen = df_selected \n",
    "        test_query = in_test_query\n",
    "    else:\n",
    "        df_chosen = df\n",
    "         # expand query in some case\n",
    "        expand_query = in_test_query.copy()\n",
    "        for word in in_test_query:\n",
    "            synonyms = functions.find_synonyms(word)\n",
    "            try:\n",
    "                expand_query.append(synonyms.pop())\n",
    "            except KeyError:\n",
    "                continue\n",
    "        test_query = expand_query   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "print(len(selected_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained glove word embeddings\n",
    "embeddings_dict = {}\n",
    "with open(\"glove/glove.6B.50d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_dict[word] = vector\n",
    "\n",
    "# create a vocabulary\n",
    "vocabulary = set()\n",
    "for sentence in df:\n",
    "    for w in sentence:\n",
    "        vocabulary.add(w)\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "corpus = []\n",
    "for sentence in df:\n",
    "    for word in sentence:\n",
    "        corpus.append(word)\n",
    "\n",
    "# create a dictionary to store the unigram probability of each word\n",
    "unigram_probabilities = {}\n",
    "for word in vocabulary:\n",
    "    unigram_probabilities[word] = functions.calculate_unigram_probability(corpus, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_dict = df_chosen.to_dict() # set in correct input format\n",
    "df_dict_vec = functions.sentence_embedding(embeddings_dict, df_dict, 0.5, unigram_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_dict = {0: test_query}\n",
    "test_query_vec = functions.sentence_embedding(embeddings_dict, test_query_dict, 0.5, unigram_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 3 similar chunks\n",
    "def get_top3_similar_chunks(query):\n",
    "    ranking = {}\n",
    "    for q in df_dict_vec:\n",
    "        ranking[q] = functions.cosine_similarity(query, df_dict_vec[q])\n",
    "    ranking = sorted(ranking.items(), key=lambda x: x[1], reverse=True)\n",
    "    if len(ranking) < 3:\n",
    "        return ranking\n",
    "    return ranking[:3]\n",
    "\n",
    "# get the top 5 similar chunks\n",
    "def get_top5_similar_chunks(query):\n",
    "    ranking = {}\n",
    "    for q in df_dict_vec:\n",
    "        ranking[q] = functions.cosine_similarity(query, df_dict_vec[q])\n",
    "    ranking = sorted(ranking.items(), key=lambda x: x[1], reverse=True)\n",
    "    if len(ranking) < 5:\n",
    "        return ranking\n",
    "    return ranking[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if the query is about refernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: BERT (Bidirectional Encoder Representations from Transformers) addresses the limitations of current techniques, particularly the unidirectionality constraint of standard language models. BERT pretrains deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As such, BERT alleviates the previously mentioned unidirectionality constraint by using a deep bidirectional architecture, allowing for better representation of contexts for both sentence-level and token-level tasks. This allows for better performance in these tasks, as BERT can be fine-tuned with just one additional output layer, without substantial task-specific architecture modifications.\n"
     ]
    }
   ],
   "source": [
    "# if the query contains 'reference','references' or 'citation' ,'citations'\n",
    "if any(x in in_test_query for x in ['reference','references','citation','citations']):\n",
    "\n",
    "    # get top 5 similar chunks\n",
    "    top_5_dict = get_top5_similar_chunks(test_query_vec[0])\n",
    "    top_5_dict\n",
    "\n",
    "    # concanate all the key values of the top 5 chunks\n",
    "    top_5_chunks = []\n",
    "    for i in range(len(top_5_dict)):\n",
    "        top_5_chunks.append(top_5_dict[i][0])\n",
    "\n",
    "    #remove \"()\" in the in_text_citations\n",
    "    in_text_citations0 = [re.sub(r'[()]', '', x) for x in top_5_chunks]\n",
    "    # extract the citations contains \";\" and split them into two citations\n",
    "    in_text_citations1 = [x.split('; ') for x in in_text_citations0]\n",
    "    # flatten the list\n",
    "    in_text_citations2 = [item for sublist in in_text_citations1 for item in sublist]\n",
    "    # create a doctionary to store the citations, the key is the citation and the value is the counts\n",
    "    in_text_citations_dict = {}\n",
    "    for i in in_text_citations2:\n",
    "        if i in in_text_citations_dict:\n",
    "            in_text_citations_dict[i] += 1\n",
    "        else:\n",
    "            in_text_citations_dict[i] = 1\n",
    "\n",
    "    # order the dictionary by the counts\n",
    "    in_text_citations_dict = dict(sorted(in_text_citations_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "    print(\"Answer: The top 5 important references are: \\n (listed in order) \\n\", list(in_text_citations_dict.keys())[:5])\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    top_3_dict = get_top3_similar_chunks(test_query_vec[0])\n",
    "\n",
    "    # the the index from the dictionary keys\n",
    "    top_3_index = [int(i[0]) for i in top_3_dict]\n",
    "    final_chunk = ''\n",
    "    for i in top_3_index:\n",
    "        final_chunk += raw_df.iloc[i][\"text\"]\n",
    "\n",
    "\n",
    "    def ask_question(paragraph, question):\n",
    "        chat_history = [\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': 'Here are some texts from a paper: ' + paragraph},\n",
    "            {'role': 'assistant', 'content': question}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=chat_history\n",
    "        )\n",
    "\n",
    "        answer = response.choices[0].message.content\n",
    "        return answer\n",
    "\n",
    "    paragraph = final_chunk\n",
    "    question = test_query_raw\n",
    "\n",
    "\n",
    "\n",
    "    answer = ask_question(paragraph, question)\n",
    "    print(\"Answer:\", answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if the query is NOT about references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# top_3_dict = get_top3_similar_chunks(test_query_vec[0])\n",
    "\n",
    "# # the the index from the dictionary keys\n",
    "# top_3_index = [int(i[0]) for i in top_3_dict]\n",
    "# final_chunk = ''\n",
    "# for i in top_3_index:\n",
    "#     final_chunk += raw_df.iloc[i][\"text\"]\n",
    "\n",
    "\n",
    "# def ask_question(paragraph, question):\n",
    "#     chat_history = [\n",
    "#         {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "#         {'role': 'user', 'content': 'Here are some texts from a paper: ' + paragraph},\n",
    "#         {'role': 'assistant', 'content': question}\n",
    "#     ]\n",
    "\n",
    "#     response = openai.ChatCompletion.create(\n",
    "#         model=\"gpt-3.5-turbo\",\n",
    "#         messages=chat_history\n",
    "#     )\n",
    "\n",
    "#     answer = response.choices[0].message.content\n",
    "#     return answer\n",
    "\n",
    "# paragraph = final_chunk\n",
    "# question = test_query_raw\n",
    "\n",
    "\n",
    "\n",
    "# answer = ask_question(paragraph, question)\n",
    "# print(\"Answer:\", answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
